# 4. Scalable Data Lakes

データレイクのスケーラビリティについて。

## 4.1 A Sneak Peek into Scalability

求められているのは、ニーズや利用が拡大してもパフォーマンスが低下せず同じ体験を保証できるアーキテクチャ。

一貫生産方式よりも生産ライン方式の方が効率的。

データレイクアーキテクチャでは、スケールアップ/ダウンとそれが必要なボトルネックを理解する必要がある。将来の新しい分析に対応可能な「ヒューチャープルーフ」な設計にする。

## 4.2 Internals of Data Lake Processing Systems

クラウドデータレイクアーキテクチャに特有な処理、データコピーとETL/ELT処理。

データコピーにおけるスケーラビリティに影響を与えるボトルネック

- コピーするファイル/オブジェクトの個数とサイズ
- データコピーツールの計算能力
- コピー処理に利用可能なネットワークキャパシティ
- リージョン間コピー

ETL/ELT処理におけるスケーラビリティに影響を与えるボトルネック

- クラスタのフォームファクターとメモリ
- 処理するファイル/オブジェクトの個数とサイズ
- データの整理方法
- ネットワークキャパシティとリージョンの境界

## 4.3 Considerations for Scalable Data Lake Solutions

データレイクソリューションをスケーラブルなものにするために考えるべきこと

- 適切なクラウド製品の選択
- キャパシティプランニング
- データ形式とジョブプロファイル

### 4.3.1 Pick the Right Cloud Offerings

ハイブリッドクラウド、マルチクラウドを選択する理由は、オンプレからクラウドへの段階的な以降、ベンダーロックインの最小限に抑える、データプライバシーなどの要件のために一部をオンプレに残さなければならない、などがある。

メリットは、柔軟性、安いものを選択すればコストが下がる、などがある。

デメリットは、運用コストが増える、クラウドから外部にデータを移動させることによるパフォーマンスの低下、深いスキルセットが必要、などがある。

IaaS, PaaS, SaaSのどれを使うか。導入の容易さ、カスタマイズの柔軟性、リソース増減の粒度から選択する。

### 4.3.2 Plan for Peak Capacity

キャパシティプランニングのための第一歩は需要の予測。SLAとビジネスニーズ、リソースの利用状況の理解、需要のピークと利用状況のピーク、スケールアウトかスケールアップか、から予測を立てる。

### 4.3.3 Data Formats and Job Profile

データ形式の選択は、データレイクのパフォーマンスとスケーラビリティに大きな影響を与える。

データレイクハウスでは、Apache Parquetや、ParquetがベースとなっているDelta Lake, Apache Icevergがデータレイクソリューションの最適なデータ形式として広く使われるようになっている。
