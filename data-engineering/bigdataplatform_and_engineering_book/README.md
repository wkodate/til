# **第1章 ［入門］データ分析基盤**

## データ分析基盤の変遷

シングルノード → マルチノード → クラウド

シングルノード時代は、個人のPCで分析していたがデータが増えてきてマルチノード(クラスタ)で複数のノードでデータを操作する必要が出てきた。Apache Hadoop、Apache Spark、Apache Hive、Apache Kafkaが代表的なプロダクト。

マルチノードの課題は、ユーザや処理の増加によるリソース不足。ストレージと計算能力を分離できるので無限にスケールできる。主なクラウドサービスは、AWS、GCP、Azure。

主なビッグデータシステムのサービスは、データ保存、データ処理、メタデータ連携、データ利用(SQL)、の4つ。

## 処理基盤、クラスタの変遷

分散処理の初期は、自前でコンセンサスアルゴリズムを実装していた。

シングルノードではスレッド処理で分散していたが、スケールさせるためにはノードのスケールアップが必要。CPUやメモリをスケールアップできてももディスクのread/writeに限界がある。分散処理ではスケールアウトで複数ノードでスケールできる。

Apache ZooKeeperでノード間のやりとりの技術が進化し、Apache Hadoop, Apache Hive, Apache SparkなどのHadoopエコシステムによって大きく分散処理が認知され始めた。

MPPDB(Massively parallel processing database)。RDBのような構造化データを処理するDB。Amazon RedshiftやGoogle BigQueryなど。

HadoopやMPPDBがクラウドで使われ始める。クラウドによってストレージと計算能力が分離したので、k8sなどのコンテナサービスなどでも使われるようになった。

## データの変遷

データの増加は、データによる意思決定の増加、データの機密性の増加、データの種類(決済データ、ログデータ、ストリーミングなど)の増加、活用方法の拡大(不正検知、パーソナライズ、AIなど)などをもたらした。

## データエンジニアのスキルセット

- 分散システムの構築管理
- データの取り込みや、ETLを通したデータパイプラインの最適化
- データが格納されているストレージの管理
- ユーザへのアクセス環境提供

## データにおける開発の変遷

個人 → データプロフェッショナル → 全員参加

データエンジニアが分析基盤を構築した後、データの利用者がなにかしたいときにデータエンジニアへの依頼が殺到し、本来のシステム作り以外のことにリソースを割くことになってしまった。

このためDataOpsとセルフサービスモデルいう考えが生まれた。

DataOpsは、分析基盤の保守運用ではなく開発に集中する。

セルフサービスモデルは、データ利用者がデータエンジニアに依存せず自身でデータ活用の処理を行う。

# **第2章 データエンジニアリングの基礎知識**

コレクティングレイヤー、プロセッシングレイヤー、ストレージレイヤー、アクセスレイヤー

## コレクティングレイヤー

ストリーミング、バッチ、プロビジョニングの方法でデータを集めるレイヤー。

ストリーミングは、絶え間なく流れるデータをプロセッシングレイヤーへ渡す。データが途切れないのでリリース難易度が高い。

バッチは、データのまとまりをプロセッシングレイヤーへ渡す。ジョブが多いのでスループットが大事。

プロビジョニングは、データパイプラインに乗せる前にとりあえずデータ分析基盤にデータを送ってみる。自由度は高いが、不要なデータが溜まるので、ライフサイクルなど検討が必要。

## プロセッシングレイヤー

保存されたデータやメタデータに対して操作を行うレイヤー。

ETL、データラングリング、暗号化、データ品質計算/メタデータ計算

データラングリングは、非構造化データを構造化データにしたり、データに付加価値を付ける作業。データストラクチャリング、データクレンジング、データエンリッチングに分かれる。ETLのほうが正規な」ワークフローで定義されるのに対して、データラングリングはワークフローで定義できないような方法でデータから価値を見つける。

データストラクチャリングは、非構造化データを構造化データに変換。

データクレンジングは、重複データや壊れているデータ、特定のフォーマットに沿っていないでデータを排除する。

データエンリッチングは、分析に必要な情報を付与。JOINなどによる特定のカラム追加など。

暗号化の方法として、ディアイデンティフィケーションと呼ばれる、データを残しつつ個人を特定されにくくする方法がある。コーホートパターンで似た情報のデータ同士を入れ替えたり、サブトラクトでデータを四則演算をして元の値を分からなくして特定しにくくする。

## ストレージレイヤー

データやメタデータを保存するレイヤー。対障害性が高く高速な処理を行えるディスクが求められる。

不要なデータは、削除するか、コストの安いストレージへアーカイブする。

データは5つのゾーンに分割して配置することが一般的。これによって、ライフサイクルの設定や、プロセッシングレイヤーでの処理、コレクティングレイヤーからの配置、アクセスレイヤーからのアクセス権限管理が容易になる。

ローゾーン: データレイクの生データを置く。ExcelやPDFのバイナリデータもそのまま保存。

ゴールドゾーン: データ基盤における主要なゾーン。データマートやデータウェアハウスの役割。

ステージングゾーン: イミュータブルなデータの提供。データウェアハウスとデータレイクの間くらい。ゴールドゾーンのデータ修復。昨今はIcebergのタイムトラベル機能でデータを遡ることができる。

クォレンティーンゾーン: 機密情報を保持するための隔離されたゾーン。

テンポラリーゾーン: プロビジョニングデータを配置するゾーン。

## アクセスレイヤー

データ分析基盤とユーザのインターフェースを持つレイヤー。

GUI、BIツール(SQL)、ストレージへの直接アクセス、メッセージキューのインターフェースがある。

GUIの提供する機能は、メタデータ参照/更新、データ分析基盤へのオペレーション。また、これらのAPI提供も

ストレージへの直接アクセスは、都度テーブル作成をせずにスキーマオンリードでアドホックに直接読み書きする。
